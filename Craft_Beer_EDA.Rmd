---
title: "Craft_Beer_EDA"
author: "Devin McCormack"
date: "4/25/2018"
output: html_document
---


## Data Overview
Here you introduce the data sources, the intent of the EDA, etc. The data source is https://www.kaggle.com/nickhould/craft-cans/data. data is in two tables, beers and breweries that contains information about different craft beers and craft breweries, respectively. Check codebook.xlsx for more info about the columns. 


# Load Data

```{r message=FALSE, warning=FALSE, load_data }
library(tidyverse)
library(gridExtra)

beers<-read.csv("craft-cans/beers.csv")
breweries<-read.csv("craft-cans/breweries.csv")
```

# Data Cleaning
Here you explore data structure and clean data if necessary. Note data formats, types and meaning

```{r summary_beers}
summary(beers)

```

As expected, Most American Craft Beers are IPAs, and often are an "American Style" Beer. There are interesting duplicates in the name category, so I'll need to explore that to make sure there is some reason behind the duplication.


```{r summary_breweries}
summary(breweries)

```

Portland looks to be the top city of craft breweries, but Colorado is the top state. I'm suspicious of Portland's top spot only because I know there are at least two major cultural cities with the name (ME and OR) - although Portland, OR certainly has a craft brew reputation. There are suspicious duplications in brewery names, so I'll have to explore that a bit more before visualization as well. 

Another note is that while beers has an unnecessary X column that can be dropped,
breweries NEEDs the X because it is the primary key. However it should be renamed.

The brewery table needs to strip the whitespace from the state column as well.

```{r message=FALSE, warning=FALSE, drop_X}
beers<-dplyr::select(beers,-X)
breweries<-dplyr::rename(breweries,brewery_id=X)
summary(breweries)
```
```{r make_brewery_id_Factor}
beers$brewery_id<-as.factor(beers$brewery_id)
breweries$brewery_id<-as.factor(breweries$brewery_id)

```


```{r strip_state_whitespace}

levels(breweries$state) <- trimws(levels(breweries$state))
summary(breweries)

```


```{r Analyze_nonstophefhop_duplicates}
beers%>%
  filter(name=='Nonstop Hef Hop')
```

There are straight up duplicates. There is no distinguishing difference between the two. Duplicates can be removed.

```{r Analyze_dale_duplicates}
beers%>%
  filter(name=="Dale's Pale Ale")
```

This is interesting. There are multiple sizes AND potentially multiple locations for breweries. There are still duplicates, though.

```{r Analyze_beer_duplicates}
beers%>%
  group_by(name)%>%
  filter(n()>1)%>%
  arrange(name)
```

Complete duplicates should be collapsed, but duplicates on only name need to be handled differently.


```{r check_distinct_beer}
  summary(distinct(beers,abv,ibu,name,style,brewery_id,ounces,.keep_all=TRUE))
```

This does well! Oktoberfest is a generic name, and Dale's has 4 varietals (potentially).

```{r remove_duplicates_beer}
beers<-distinct(beers,abv,ibu,name,style,brewery_id,ounces,.keep_all=TRUE)
```

We need to do the same with breweries.

```{r Analyze_brewery_duplicates}
breweries%>%
  group_by(name)%>%
  filter(n()>1)%>%
  arrange(name)
```


Blackrocks is super suspicious, as the city is THE SAME, but the state is different.
Checking online, Blackrocks is ONLY in MI.

Blue Mountain is a legitimate split, BM Brewery splits their normal and specialty aged
beers between the two locations

Lucette is clearly a misspelling. Hilariously, BOTH are misspellings. Lucette is
in Menomonie, WI

Oskar Blues, like BM, actually has two locations (in reality they have
several locations and breweries). However I doubt there is a type division

Otter Creek used to be in Waterbury before expanding and moving to Middlebury

Sly fox has two actual locations

Summit has a spelling discrepancy. We want to keep "St. Paul".

In summary, Only three changes need to be made: to Blackrocks, Lucette, and Summit.
Importantly, we need to preserve the joinability of the tables by altering the
brewery_id on affected beers.


```{r Analyze_Blackrocks_beers}
beers%>%
  filter(brewery_id %in% c(12,95))
```

```{r Clean_Blackrocks_beers}
beers%>%
  mutate(brewery_id=replace(brewery_id,brewery_id==95,12))->beers
## Test
beers%>%
  filter(brewery_id %in% c(12,95))
```

```{r Analyze_lucette_beers}
beers%>%
  filter(brewery_id %in% c(377,456))
```

```{r Clean_lucette_beers}
beers%>%
  mutate(brewery_id=replace(brewery_id,brewery_id==377,456))->beers
## Test
beers%>%
  filter(brewery_id %in% c(377,456))
```

```{r Analyze_summit_beers}
beers%>%
  filter(brewery_id %in% c(58,138))
```

```{r Clean_summit_beers}
beers%>%
  mutate(brewery_id=replace(brewery_id,brewery_id==138,58))->beers
## Test
beers%>%
  filter(brewery_id %in% c(58,138))
```

So we will want to remove the breweries with the following IDs: 95, 377, and 138.
Additionally, We need to modify Lucette to have to correct spelling.
Each has only one outlier

```{r remove_duplicate_breweries}
breweries%>%
  filter(!brewery_id %in% c(95,377,138))->breweries

## Test
breweries%>%
  group_by(name)%>%
  filter(n()>1)%>%
  arrange(name)
```

Now just to fix Menomonie

```{r check_WI}
breweries%>%
  filter(state=='WI')

```

```{r check_if_other_menomonie}
breweries%>%
  filter(city=="Menominie")

```

```{r clean_menomonie}
breweries%>%
  mutate(city = dplyr::recode(city, "Menominie" = "Menomonie"))->breweries
## Test
breweries%>%
  filter(brewery_id==456)
```

Lets take one more look at the data summaries before we break into visualization

```{r "clean_data_summaries beers"}
summary(beers)
str(beers)
```

```{r "clean_data_summaries breweries"}
summary(breweries)
str(breweries)
```

# Visualizations

## Univariate Analysis

```{r "univariate_plot abv"}
abvcolor<-aes(color=I('gray'),fill=I('tomato'))

ggplot(data=beers,aes(x=abv))+
  geom_histogram(binwidth=.002,abvcolor)
```

Many beers have ABV of .05. 5% is pretty standard beer alcohol content. It skews
right - and I think this is because craft beers generally try to be unique and have
something that makes it different than a domestic. Higher alcohol content is a 
simple way to justify the craft value.

```{r "univariate_plot ibu"}
ibucolor<-aes(color=I('gray'),fill=I('limegreen'))

ggplot(data=beers,aes(x=ibu))+
  geom_histogram(ibucolor,binwidth = 5)
```

IBUs measure the bitterness. There was (maybe still is) a IPA craze in craft beer.
It is a weird machismo thing to max out bitterness at the expense of balance. It
is a common way to distinguish yourself - check the peak at 100. The otherwise
bimodality is likely due to most beer types have IBUs under 25, but IPAs and other
high-hopped beers seek for near 75.

```{r "univariate_plot oz"}
ozcolor<-aes(color=I('gray'),fill=I('cadetblue'))

ggplot(data=beers,aes(x=ounces))+
  geom_bar(ozcolor)+
  scale_x_continuous(breaks=seq(0,32,4))
```

There are very common beer can sizes. 12 oz, 16 oz etc. There are some oddballs.

```{r fig.height=8.5, "univariate_plot style"}

ggplot(data=beers,aes(x=reorder(style,style,function(x)+length(x))))+
  geom_bar()+
  scale_y_log10()+
  coord_flip()

```

Note the log scale.American style beers dominate the american craft brew scene. 
It is noteworthy that lagers are technically more difficult and expensive to make,
and a lot of craft breweries brew ales. 
It is also noteworthy that there are around 10 beers without a style attached to them.

```{r "join data"}
joineddata<-dplyr::left_join(beers,breweries, by="brewery_id",suffix=c(".beer",".brewer"))
summary(joineddata)
```
```{r message=FALSE, "univariate_plot brewery" }
top20brew<-joineddata %>%
  count(brewery_id) %>%
  top_n(20)

ggplot(data=subset(joineddata,brewery_id %in% top20brew$brewery_id),
       aes(x=reorder(name.brewer,name.brewer, function(x)+length(x))))+
  geom_bar()+
  coord_flip()

```

Some breweries are going crazy pumping out different beers.



I don't think looking at name will yield much, as the names are largely unique.


Now lets look at the breweries table closer.

```{r "univariate_plot state"}
statecolor=aes(color=I('gray'),fill=I('mediumpurple'))
ggplot(data=breweries, aes(x=reorder(state,state, function(x)+length(x))))+
  geom_bar(statecolor)+
  coord_flip()

```

Colorado is king! Colorado has a huge brewing history, as well as Michigan. 
California is just huge. Oregon has a reputation for craft breweries,
especially in Portland.

Speaking of Portland, there are two important Portlands, so I want to check if 
duplicate city names in different states is a factor. likely just need to create
a new variable that combines the two.

```{r create_citystate}
breweries %>%
  mutate(citystate=interaction(city,state,sep=", "))->breweries
summary(breweries)
```

We can see that the number of "Portland" cities is not equal to the number of 
"Portland, OR", meaning that Portland, ME has a few craft breweries.

```{r message=FALSE, "univariate_plot citystate"}

top10citystate<-breweries %>%
  count(citystate) %>%
  top_n(10)

ggplot(data=subset(breweries,citystate %in% top10citystate$citystate),
       aes(x=reorder(citystate,citystate, function(x)+length(x))))+
  geom_bar(statecolor)+
  coord_flip()


```

Both Portlands are in the top 10.


### Univariate Summary
#### What is the structure of your dataset?

standard relational dataset.

#### What is/are the main feature(s) of interest in your dataset?
Things like ABV and IBU are important, as well as location.

#### What other features in the dataset do you think will help support your investigation into your feature(s) of interest?

style will be interesting to correlate with ABV and IBU.

#### Did you create any new variables from existing variables in the dataset?

I created a citystate variable to account for same city names in different states

#### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?

There is a slight tail on abv, which makes sense. Some beers are high alcohol content by design.
There is a bimodality (or tri-modality) in IBUs, which is likely tied to unique
beer styles that are know for bitterness, like IPAs.

## Bivariate Analysis

I should've just done this in the beginning, but I'll work exclusively on the 
joined data now.

```{r "join data multi"}
joineddata<-dplyr::left_join(beers,breweries, by="brewery_id",suffix=c(".beer",".brewer"))
summary(joineddata)
```

Start with a ggpairs, as it plots all the bivariates at once.
```{r  message = FALSE, warning = FALSE, fig.width=8.5, fig.height=8.5, ggpairs_analysis}
library(GGally)
library(scales)
library(memisc)

ggpairs(dplyr::select(joineddata,
                      -ends_with("id"),-starts_with("name."),-starts_with("city"),-style,-state),
        lower = list(continuous = wrap("points", shape = I('.'))),
        upper = list(combo = wrap("box", outlier.shape = I('.'))))
        
```

Unfortunately, most of the data has a huge number of factors and isn't ameniable to 
pairplotting. But this is still useful.

```{r "bivariate_plot abv_vs_ibu"}

ggplot(data=joineddata,aes(x=abv,y=ibu))+
  geom_point(alpha=.5)+
  geom_smooth(method="lm",formula=y~x)+
  geom_density2d()

with(joineddata,cor.test(abv,ibu))
```

There is a correlation between ABV and IBU. There is no technical reason for these
to be correlated, as alcohol content and ibu are adjusted with different components
of beer. However, it is a competitive advantage in niche craft markets to be
exceptional. the hoppiest and most alcoholic beer is a branding edge that a 
small craft brewery would strive to have.

```{r fig.height=8.5, "bivariate_plot abv state"}

ggplot(data=joineddata,aes(x=reorder(state,-abv,median,na.rm = TRUE), y=abv))+
  geom_jitter(alpha=.3,color='tomato')+
  geom_boxplot(alpha=.5,fill='tomato')+
  stat_summary(fun.y="mean",geom="point",color="green",shape=8,size=2)+
  coord_flip()
```

Utah has a oddball beer law, saying beer must be 4% ABV max, whihc explains their 
location! Many of the states have pretty wide spreads.

```{r fig.height=8.5, "bivariate_plot ibu state"}

ggplot(data=joineddata,aes(x=reorder(state,-ibu,median,na.rm = TRUE), y=ibu))+
  geom_jitter(alpha=.3,color='limegreen')+
  geom_boxplot(alpha=.5,fill='limegreen')+
  stat_summary(fun.y="mean",geom="point",color="red",shape=8,size=2)+
  coord_flip()
```

There is an interesting narrative of having mostly midwestern states near the bottom
of IBUs, and having southern and costal states near the top. it isnt a perfect narrative.

This needs to be loaded up into tableau for some interesting maps.

Another important thing to do is to actually make a region variable! If we categorize
the states into the four regions: Northeast, South, Midwest, and West; and into
divisions: New England, Mid-atlantic, East North Central, West North Central,
South atlantic, East South Central, West South Central, Mountain, and Pacific; we 
may see cultural or regional differences with better clarity.

```{r "create_states_variables"}
state<- unique(joineddata$state)
  
divisions<-data.frame(state)
```

```{r "create_divisions_variables"}
divisions<-divisions%>%
  mutate(division=case_when(state %in% c("CT","ME","MA","NH","RI","VT") ~ "New England",
                            state %in% c("NJ","NY","PA") ~ "Mid-Atlantic",
                            state %in% c("WV","MD","DE","DC","VA","NC","SC","GA","FL") ~ "South Atlantic",
                            state %in% c("KY","TN","MS","AL") ~ "East South Central",
                            state %in% c("MI","OH","IN","IL","WI") ~ "East North Central",
                            state %in% c("MN","IA","MO","ND","SD","NE","KS") ~ "West North Central",
                            state %in% c("OK","AR","LA","TX") ~ "West South Central",
                            state %in% c("CO","NM","WY","MT","ID","UT","AZ","NV") ~ "Mountain",
                            state %in% c("WA","OR","CA","AK","HI") ~ "Pacific",
                            TRUE ~ "OTHER"))
```

```{r "create_regions_variables"}
divisions<-divisions%>%
  mutate(region=case_when(division %in% c("New England","Mid-Atlantic") ~ "Northeast",
                            division %in% c("South Atlantic","East South Central","West South Central") ~"South",
                            division %in% c("East North Central","West North Central") ~"Midwest",
                            division %in% c("Mountain","Pacific") ~ "West",
                            TRUE ~ "OTHER"))
```

Now we can reupdate the joineddata by joining our new table!

```{r "join_in_regions"}
joineddata<-joineddata %>%
  left_join(divisions,by="state")
```

Lets look at divisions and regions for ABV and IBU

```{r fig.height=8.5, "bivariate_plot abv division"}

ggplot(data=joineddata,aes(x=reorder(division,-abv,median,na.rm = TRUE), y=abv))+
  geom_jitter(alpha=.3,color='tomato')+
  geom_boxplot(alpha=.5,fill='tomato')+
  stat_summary(fun.y="mean",geom="point",color="green",shape=8,size=2)+
  coord_flip()
```

Every division seems to keep it pretty close to 6%, but it looks like the southwestern
states like slightly lower abv than the great lakes. Maybe more ice beers in the 
colder climate?

```{r fig.height=8.5, "bivariate_plot ibu division"}

ggplot(data=joineddata,aes(x=reorder(division,-ibu,median,na.rm = TRUE), y=ibu))+
  geom_jitter(alpha=.3,color='limegreen')+
  geom_boxplot(alpha=.5,fill='limegreen')+
  stat_summary(fun.y="mean",geom="point",color="red",shape=8,size=2)+
  coord_flip()
```


This is neat, the pacific coast states have a huge range in IBUs, while the heartland
states maybe don't like the bitterness for the sake of bitterness.

```{r fig.height=8.5, "bivariate_plot abv region"}

ggplot(data=joineddata,aes(x=reorder(region,-abv,median,na.rm = TRUE), y=abv))+
  geom_jitter(alpha=.3,color='tomato')+
  geom_boxplot(alpha=.5,fill='tomato')+
  stat_summary(fun.y="mean",geom="point",color="green",shape=8,size=2)+
  coord_flip()
```

the differences get even smaller. The west coast seems to be more experimental
than the other areas. Likely just a factor of number of breweries/beers.


```{r fig.height=8.5, "bivariate_plot ibu region"}

ggplot(data=joineddata,aes(x=reorder(region,-ibu,median,na.rm = TRUE), y=ibu))+
  geom_jitter(alpha=.3,color='limegreen')+
  geom_boxplot(alpha=.5,fill='limegreen')+
  stat_summary(fun.y="mean",geom="point",color="red",shape=8,size=2)+
  coord_flip()
```

Looks like the same trend holds, the midwest likes the more balanced bitterness
(influenced by budweiser in STL maybe?) while the west coast likes to experiment
more.


### Bivariate Summary
#### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?

#### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?

#### What was the strongest relationship you found?


## Multivariate Analysis

```{r "multivariate_regions"}
ggplot(data=joineddata,aes(x=abv,y=ibu,color=region))+
  geom_point(alpha=.5)+
  geom_smooth(method="lm",formula=y~x)

```

Basically no distinction within these regions, except that the south and the 
midwest have a few particularly high ABV choices.


```{r "multivariate_divisions"}
ggplot(data=joineddata,aes(x=abv,y=ibu,color=division))+
  geom_point(alpha=.5)

```


## Modeling Data
optional part, use a model to try to fit data.

```{r "Modeling with ordinal regression"}
# 
# m1 <- polr(quality ~ variable1, data = edadata, Hess=TRUE)
# m2 <- update(m1, ~ . + variable2)
# m3 <- update(m2, ~ . + variable3)
# 
# mtable(m1, m2, m3)

```

### Multivariate Summary
#### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?

#### Were there any interesting or surprising interactions between features?

#### OPTIONAL: Did you create any models with your dataset? Discuss the strengths and limitations of your model.

# Final Plots


```{r final_plot1}
# copied from above
```
Highlight the most impactful and interesting plots from above, giving a standalone discription of the plot and what it shows.

# Grand Summary and Reflection

Reflect on data quality - the difficulties and deficits of the data - and potential options to expand data collection to remedy deficits.

Reflect on data structure that appeals to common beliefs about the data, structure that challenges preconceived notions, and most importantly any surprising and un-thought-of structure that stands out.

Note on next steps (collect more data, further exploration, machine learning)